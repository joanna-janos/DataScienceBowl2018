{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Adversarial validation </h1>\n",
    "\n",
    "Main purpose of adversarial validation is checking if training and test images come from same distribution.\n",
    "\n",
    "**How does it work?**\n",
    "1. Load training images and assign them class 0.\n",
    "1. Load test images and assign them class 1.\n",
    "1. Combine training and test images, shuffle them and split into new_train and new_validation (pay attention to distribution of classes in each new dataset)\n",
    "1. Create simple model/neural network and train on new_train dataset\n",
    "1. Check metric score (accuracy) for new_validation dataset. It should be similar to value for new_train.\n",
    "1. High value means that data is from different distributions, low - the same (perfectly it should be about 50%).\n",
    "\n",
    "**Problems**\n",
    "- Images have different dimensions. -> Cropping central image with the smallest dimension from all images can be enough for this task.\n",
    "- Some test images have 3 channels. -> Getting three channels can be enough for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_bw_files = '../data/colour_model/train/bw_images.csv'\n",
    "path_to_train_colour_files = '../data/colour_model/train/colour_imgs.csv'\n",
    "path_to_test_bw_files = '../data/colour_model/test/bw_images.csv'\n",
    "path_to_test_colour_files = '../data/colour_model/test/colour_imgs.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def create_dataframe(path_to_csv_1, path_to_csv_2, marker):\n",
    "    \"\"\"Create dataframe based on 2 csv files containg paths.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path_to_csv_1 : path to first csv\n",
    "    path_to_csv_2 : path to second csv\n",
    "    marker: how should be marked images in 'Marker' column\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "            first datamframe, second dataframe\n",
    "    \"\"\"\n",
    "    df_1 = pd.read_csv(path_to_csv_1)\n",
    "    df_2 = pd.read_csv(path_to_csv_2)\n",
    "    df = pd.concat([df_1, df_2])\n",
    "    df['Marker'] = marker\n",
    "    return df\n",
    "\n",
    "def concat_and_split_df(df_1, df_2, split_factor):\n",
    "    \"\"\"Get concatenated and randomly splitted dataframes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_1 : first dataframe to concatenate\n",
    "    df_2 : second dataframe to concatenate\n",
    "    split_factor: how many percents should be in first dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "            first dataframe, second dataframe\n",
    "    \"\"\"\n",
    "    df = pd.concat([df_1, df_2])\n",
    "    df = shuffle(df)\n",
    "    elements_count = int(split_factor * len(df))\n",
    "    splitted_1_df = df[:elements_count]\n",
    "    splitted_2_df = df[elements_count:]\n",
    "    splitted_1_df.reset_index(drop=True, inplace=True)\n",
    "    splitted_2_df.reset_index(drop=True, inplace=True)\n",
    "    return splitted_1_df, splitted_2_df\n",
    "\n",
    "\n",
    "images_train_df = create_dataframe(path_to_train_bw_files, path_to_train_colour_files, 0.0)\n",
    "images_test_df = create_dataframe(path_to_test_bw_files, path_to_test_colour_files, 1.0)\n",
    "\n",
    "images_with_markers_train_df, images_with_markers_test_df = concat_and_split_df(\n",
    "    images_train_df, images_test_df, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    " \n",
    "class ImageWithMarkerDataset(Dataset):\n",
    "    def __init__(self, paths_with_markers_df, transform=None):\n",
    "        self.paths_with_markers_df = paths_with_markers_df\n",
    "        self.transform = transform\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.paths_with_markers_df)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.paths_with_markers_df['Path'][idx]).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, torch.tensor(self.paths_with_markers_df['Marker'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, CenterCrop, ToTensor\n",
    " \n",
    "the_smallest_dimension = 160 #based on EDA\n",
    "transforms = Compose([ToTensor()])\n",
    "images_with_markers_dataset_train = ImageWithMarkerDataset(images_with_markers_train_df, transforms)\n",
    "images_with_markers_dataset_test = ImageWithMarkerDataset(images_with_markers_test_df, transforms)\n",
    " \n",
    "train_dataloader = DataLoader(images_with_markers_dataset_train, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(images_with_markers_dataset_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "torch.manual_seed(1024)\n",
    " \n",
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNetwork, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(64, 128, kernel_size=3, stride=2)\n",
    "        self.conv3 = torch.nn.Conv2d(128, 256, kernel_size=2, stride=2)\n",
    " \n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.global_pool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = torch.nn.Linear(256, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    " \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    " \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.global_pool(x).squeeze()\n",
    " \n",
    "        x = self.fc(x)\n",
    "        return x\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct values in test:  0.0\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    " \n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "neural_network = SimpleNeuralNetwork()\n",
    "optimizer = optim.Adam(neural_network.parameters(), lr=0.01)\n",
    "n_epochs = 10\n",
    "correct_test = 0\n",
    "\n",
    "neural_network.train()\n",
    "for epoch in range(n_epochs):\n",
    "    for img, target in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = neural_network(img)\n",
    "        loss_value = loss(target, output)\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "with torch.no_grad():\n",
    "    neural_network.eval()\n",
    "    for img, target in test_dataloader:\n",
    "        output = neural_network(img)\n",
    "        if output.item() == target.item():\n",
    "            correct_test += 1\n",
    "        \n",
    "print('Correct values in test: ', float(correct_test)/ float(len(images_with_markers_dataset_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it is very hard for model to classify which image is from train and test dataset. \n",
    "\n",
    "`Observations:`\n",
    "- Above statement means that images are from the same distribution. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
